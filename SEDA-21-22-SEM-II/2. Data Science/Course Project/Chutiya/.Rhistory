data <- read.csv("dataset.csv")
data
#getting additional information
head(data,n=10)
print(summary.data.frame(data))
dim(data)
summary(data)
str(data)
View(data)
library(psych)
describe(data)
colnames(data)
nrow(data)
ncol(data)
#finding co relation
# getting the correlation between each variable
library(psych)
library(class)
library(caTools)
library(caret)
library(mltools)
library(data.table)
real_data <- data
dataset <- data
str(real_data)
data <- data[c(-1)]
str(data)
#changing to numeric
data$Ge0der =as.numeric(as.factor(data$Ge0der))
data$Ge0der
data$Married =as.numeric(as.factor(data$Married))
data$Married
data$Dependents=as.numeric(as.factor(data$Dependents))
data$Dependents
data$Educatio0=as.numeric(as.factor(data$Educatio0))
data$Educatio0
data$Self_Emplo1ed =as.numeric(as.factor(data$Self_Emplo1ed))
data$Self_Emplo1ed
data$Propert1_Area=as.numeric(as.factor(data$Propert1_Area))
data$Propert1_Area
str(data)
#finding correlation
cr <-cor(data)
cor(data, method = "spearman")
cor.test(data$Applica0tI0come, data$Loa0_Amou0t_Term)
cr
cor(data, method = "spearman")
library(corrplot)
cor.test(data$Applica0tI0come, data$Loa0_Amou0t_Term)
corrplot(cr)
corrplot(cr, method = "pie")
crrr<-cor(data, method = "spearman")
corrplot(crrr, method = "pie")
cor(data, method = "spearman")
cor.test(data$Applica0tI0come, data$Loa0_Amou0t_Term)
library(corrplot)
corrplot(cr)
corrplot(cr, method = "pie")
library(ISLR)
library(caret)
data <- read.csv("dataset.csv")
data
set.seed(300)
dataset<-data
#changing to numeric
data$Ge0der =as.numeric(as.factor(data$Ge0der))
data$Married =as.numeric(as.factor(data$Married))
data$Dependents=as.numeric(as.factor(data$Dependents))
data$Educatio0=as.numeric(as.factor(data$Educatio0))
data$Self_Emplo1ed =as.numeric(as.factor(data$Self_Emplo1ed))
data$Propert1_Area=as.numeric(as.factor(data$Propert1_Area))
#SCALING AND SAMPLING
data_scaled = as.data.frame(scale(data[,7:10]))
data_scaled$Self_Emplo1ed
dataset$Self_Emplo1ed
data_scaled$Self_Emplo1ed = dataset$Self_Emplo1ed
data_scaled$Self_Emplo1ed
View(data)
#SCALING AND SAMPLING
data_scaled = as.data.frame(scale(data[,7:10]))
data_scaled$Self_Emplo1ed = dataset$Self_Emplo1ed
data_scaled$Educatio0 = dataset$Educatio0
data_scaled$Dependents = dataset$Dependents
data_scaled$Married = dataset$Married
data_scaled$Ge0der = dataset$Ge0der
data_scaled$Loa0_Id = dataset$Loa0_Id
data_scaled$Credit_Histor1 = dataset$Credit_Histor1
data_scaled$Propert1_Area = dataset$Propert1_Area
data_scaled$Loa0_Status = dataset$Loa0_Status
View(data_scaled)
data
str(data)
data=data_scaled[1:11]
str(data)
str(data_scaled)
data=data_scaled[1:11]
is.null(data)
count(is.null(data))
sum(is.null(data))
data=data_scaled[1:11]
str(data)
data <- dummyVars(" ~ .", data=data)
str(data)
str(data)
newdata <- data.frame(predict(data, newdata = dataset))
str(newdara)
str(newdata)
dataset<-cbind(newdata,dataset[13])
str(dataset)
dataset$Loa0_Status<-as.factor(dataset$Loa0_Status)
str(dataset)
table(dataset$Loa0_Status)
library(ROSE)
over <- ovun.sample(Loa0_Status~., data=dataset, method= "over",N=800)$data
str(over)
df <- read.csv("datasetHA.csv")
head(df)
head(df)
keeps <- c("Reference.Area", "Time.Period","Observation.Value")
df <- df[keeps]
head(df)
sum(is.null(df))
#loading  dataset
data <- read.csv("dataset.csv")
data
#getting additional information
head(data,n=10)
print(summary.data.frame(data))
dim(data)
summary(data)
str(data)
View(data)
library(psych)
describe(data)
colnames(data)
nrow(data)
ncol(data)
#finding co relation
# getting the correlation between each variable
library(psych)
library(class)
library(caTools)
library(caret)
library(mltools)
library(data.table)
real_data <- data
dataset <- data
str(real_data)
data <- data[c(-1)]
str(data)
#changing to numeric
data$Ge0der =as.numeric(as.factor(data$Ge0der))
data$Ge0der
data$Married =as.numeric(as.factor(data$Married))
data$Married
data$Dependents=as.numeric(as.factor(data$Dependents))
data$Dependents
data$Educatio0=as.numeric(as.factor(data$Educatio0))
data$Educatio0
data$Self_Emplo1ed =as.numeric(as.factor(data$Self_Emplo1ed))
data$Self_Emplo1ed
data$Propert1_Area=as.numeric(as.factor(data$Propert1_Area))
data$Propert1_Area
str(data)
#finding correlation
cr <-cor(data)
cor(data, method = "spearman")
cor.test(data$Applica0tI0come, data$Loa0_Amou0t_Term)
library(corrplot)
corrplot(cr)
corrplot(cr, method = "pie")
library(ISLR)
library(caret)
data <- read.csv("dataset.csv")
data
set.seed(300)
dataset<-data
#changing to numeric
data$Ge0der =as.numeric(as.factor(data$Ge0der))
data$Married =as.numeric(as.factor(data$Married))
data$Dependents=as.numeric(as.factor(data$Dependents))
data$Educatio0=as.numeric(as.factor(data$Educatio0))
data$Self_Emplo1ed =as.numeric(as.factor(data$Self_Emplo1ed))
data$Propert1_Area=as.numeric(as.factor(data$Propert1_Area))
#SCALING AND SAMPLING
data_scaled = as.data.frame(scale(data[,7:10]))
data_scaled$Self_Emplo1ed = dataset$Self_Emplo1ed
data_scaled$Educatio0 = dataset$Educatio0
data_scaled$Dependents = dataset$Dependents
data_scaled$Married = dataset$Married
data_scaled$Ge0der = dataset$Ge0der
data_scaled$Loa0_Id = dataset$Loa0_Id
data_scaled$Credit_Histor1 = dataset$Credit_Histor1
data_scaled$Propert1_Area = dataset$Propert1_Area
data_scaled$Loa0_Status = dataset$Loa0_Status
View(data_scaled)
str(data)
data=data_scaled[1:11]
data <- dummyVars(" ~ .", data=data)
newdata <- data.frame(predict(data, newdata = dataset))
dataset<-cbind(newdata,dataset[13])
dataset$Loa0_Status<-as.factor(dataset$Loa0_Status)
str(dataset)
table(dataset$Loa0_Status)
library(ROSE)
over <- ovun.sample(Loa0_Status~., data=dataset, method= "over",N=800)$data
str(over)
table(over$Loa0_Status)
set.seed(240)
dataset<-over
samplesplit<-sample.split(dataset$Loa0_Status,SplitRatio = 0.75)
head(samplesplit,n=25)
length(samplesplit)
head(samplesplit,n=25)
length(samplesplit)
#Spliting data as training and test set. Using createDataPartition() function from caret
indxTrain <- createDataPartition(y = dataset$Loa0_Status,p = 0.75,list = FALSE)
training <- dataset[indxTrain,]
testing <- dataset[-indxTrain,]
#Checking distibution in origanl data and partitioned data
prop.table(table(training$Loa0_Status)) * 100
prop.table(table(testing$Loa0_Status)) * 100
prop.table(table(dataset$Loa0_Status)) * 100
trainX <- training[,names(training) != "dataset"]
preProcValues <- preProcess(x = trainX,method = c("center", "scale"))
preProcValues
View(preProcValues)
set.seed(400)
ctrl <- trainControl(method="repeatedcv",repeats = 3) #,classProbs=TRUE,summaryFunction = twoClassSummary)
knnFit <- train(Loa0_Status ~ ., data = training, method = "knn", trControl = ctrl, preProcess = c("center","scale"), tuneLength = 20)
#Output of kNN fit
knnFit
plot(knnFit)
#Output of kNN fit
View(knnFit)
knnPredict <- predict(knnFit,newdata = testing )
#Get the confusion matrix to see accuracy value and other parameter values
confusionMatrix(knnPredict, testing$Loa0_Status )
#RANDOMFOREST
#Spliting data as training and test set. Using createDataPartition() function from caret
indxTrain1 <- createDataPartition(y = dataset$Loa0_Status,p = 0.75,list = FALSE)
training1 <- dataset[indxTrain,]
testing1 <- dataset[-indxTrain,]
trctrl <- trainControl(method = "repeatedcv" , number = 10, repeats = 3)
tunegrid <- expand.grid(.mtry=6)
rf_default <- train(Loa0_Status~.,
data=training1,
method='rf',
metric='Accuracy',
tuneGrid=tunegrid,
trControl=trctrl)
print(rf_default)
plot(rf_default)
confusionMatrix(table(test_pred_grid,testing1$Loa0_Status))
rfPredict <- predict(rf_default,newdata = testing )
#Get the confusion matrix to see accuracy value and other parameter values
confusionMatrix(rfPredict, testing$Loa0_Status )
#svm
data<-real_data
library('caret')
str(data)
head(data)
#changing to numeric
data$Ge0der =as.numeric(as.factor(data$Ge0der))
data$Ge0der
data$Married =as.numeric(as.factor(data$Married))
data$Married
data$Dependents=as.numeric(as.factor(data$Dependents))
data$Dependents
data$Educatio0=as.numeric(as.factor(data$Educatio0))
data$Educatio0
data$Self_Emplo1ed=as.numeric(as.factor(data$Self_Emplo1ed))
data$Self_Emplo1ed
data$Propert1_Area=as.numeric(as.factor(data$Propert1_Area))
data$Propert1_Area
data <- data[c(-1)]
str(data)
set.seed(3033)
intrain <- createDataPartition(y= data$Loa0_Status , p=0.7,list = FALSE)
training <- data[intrain,]
testing <- data[-intrain,]
dim(training);
dim(testing);
anyNA(data)
summary(data)
#factorizing
training[["Loa0_Status"]] = factor(training[["Loa0_Status"]])
trctrl <- trainControl(method = "repeatedcv" , number = 10, repeats = 3)
svm_linear <- train(Loa0_Status~.,data = training, method = "svmLinear"
,trControl = trctrl
, preProcess = c("center" , "scale"),
tuneLength = 10)
svm_linear
test_predict <- predict(svm_linear,newdata = testing)
test_predict
confusionMatrix(table(test_predict,testing$Loa0_Status))
length(data$Loa0_Status)
length(test_predict)
length(testing)
grid <- expand.grid(C= c(0.01,0.05,0.1,0.25,0.5,0.75,1,1.25,1.5,1.75,2.5))
set.seed(3233)
svm_linear_grid <-train(Loa0_Status~. , data = training,method="svmLinear"
, trControl = trctrl,
preProcess = c("center","scale"),
tuneGrid = grid,
tuneLength = 10)
svm_linear_grid
plot(svm_linear_grid)
test_pred_grid <- predict(svm_linear_grid,newdata = testing)
test_pred_grid
confusionMatrix(table(test_pred_grid,testing$Loa0_Status))
summary(data)
svm_linear_grid
grid <- expand.grid(C= c(0.01,0.05,0.1,0.25,0.5,0.75,1,1.25,1.5,1.75,2.5))
set.seed(3233)
svm_linear_grid <-train(Loa0_Status~. , data = training,method="svmLinear"
, trControl = trctrl,
preProcess = c("center","scale"),
tuneGrid = grid,
tuneLength = 10)
source("B:/VIT/2. Data Science/Course Project/Chutiya/FinalDraft.R", echo=TRUE)
#loading  dataset
data <- read.csv("dataset.csv")
data
#getting additional information
head(data,n=10)
print(summary.data.frame(data))
dim(data)
summary(data)
str(data)
View(data)
library(psych)
describe(data)
colnames(data)
nrow(data)
ncol(data)
#finding co relation
# getting the correlation between each variable
library(psych)
library(class)
library(caTools)
library(caret)
library(mltools)
library(data.table)
real_data <- data
dataset <- data
str(real_data)
data <- data[c(-1)]
str(data)
#changing to numeric
data$Ge0der =as.numeric(as.factor(data$Ge0der))
data$Ge0der
data$Married =as.numeric(as.factor(data$Married))
data$Married
data$Dependents=as.numeric(as.factor(data$Dependents))
data$Dependents
data$Educatio0=as.numeric(as.factor(data$Educatio0))
data$Educatio0
data$Self_Emplo1ed =as.numeric(as.factor(data$Self_Emplo1ed))
data$Self_Emplo1ed
data$Propert1_Area=as.numeric(as.factor(data$Propert1_Area))
data$Propert1_Area
str(data)
#finding correlation
cr <-cor(data)
cor(data, method = "spearman")
cor.test(data$Applica0tI0come, data$Loa0_Amou0t_Term)
library(corrplot)
corrplot(cr)
corrplot(cr, method = "pie")
library(ISLR)
library(caret)
data <- read.csv("dataset.csv")
data
set.seed(300)
dataset<-data
#changing to numeric
data$Ge0der =as.numeric(as.factor(data$Ge0der))
data$Married =as.numeric(as.factor(data$Married))
data$Dependents=as.numeric(as.factor(data$Dependents))
data$Educatio0=as.numeric(as.factor(data$Educatio0))
data$Self_Emplo1ed =as.numeric(as.factor(data$Self_Emplo1ed))
data$Propert1_Area=as.numeric(as.factor(data$Propert1_Area))
#SCALING AND SAMPLING
data_scaled = as.data.frame(scale(data[,7:10]))
data_scaled$Self_Emplo1ed = dataset$Self_Emplo1ed
data_scaled$Educatio0 = dataset$Educatio0
data_scaled$Dependents = dataset$Dependents
data_scaled$Married = dataset$Married
data_scaled$Ge0der = dataset$Ge0der
data_scaled$Loa0_Id = dataset$Loa0_Id
data_scaled$Credit_Histor1 = dataset$Credit_Histor1
data_scaled$Propert1_Area = dataset$Propert1_Area
data_scaled$Loa0_Status = dataset$Loa0_Status
View(data_scaled)
str(data)
data=data_scaled[1:11]
data <- dummyVars(" ~ .", data=data)
newdata <- data.frame(predict(data, newdata = dataset))
dataset<-cbind(newdata,dataset[13])
dataset$Loa0_Status<-as.factor(dataset$Loa0_Status)
str(dataset)
table(dataset$Loa0_Status)
library(ROSE)
over <- ovun.sample(Loa0_Status~., data=dataset, method= "over",N=800)$data
str(over)
table(over$Loa0_Status)
set.seed(240)
dataset<-over
samplesplit<-sample.split(dataset$Loa0_Status,SplitRatio = 0.75)
head(samplesplit,n=25)
length(samplesplit)
#Spliting data as training and test set. Using createDataPartition() function from caret
indxTrain <- createDataPartition(y = dataset$Loa0_Status,p = 0.75,list = FALSE)
training <- dataset[indxTrain,]
testing <- dataset[-indxTrain,]
#Checking distibution in origanl data and partitioned data
prop.table(table(training$Loa0_Status)) * 100
prop.table(table(testing$Loa0_Status)) * 100
prop.table(table(dataset$Loa0_Status)) * 100
trainX <- training[,names(training) != "dataset"]
preProcValues <- preProcess(x = trainX,method = c("center", "scale"))
preProcValues
set.seed(400)
ctrl <- trainControl(method="repeatedcv",repeats = 3) #,classProbs=TRUE,summaryFunction = twoClassSummary)
knnFit <- train(Loa0_Status ~ ., data = training, method = "knn", trControl = ctrl, preProcess = c("center","scale"), tuneLength = 20)
#Output of kNN fit
knnFit
plot(knnFit)
knnPredict <- predict(knnFit,newdata = testing )
#Get the confusion matrix to see accuracy value and other parameter values
confusionMatrix(knnPredict, testing$Loa0_Status )
#RANDOMFOREST
#Spliting data as training and test set. Using createDataPartition() function from caret
indxTrain1 <- createDataPartition(y = dataset$Loa0_Status,p = 0.75,list = FALSE)
training1 <- dataset[indxTrain,]
testing1 <- dataset[-indxTrain,]
trctrl <- trainControl(method = "repeatedcv" , number = 10, repeats = 3)
tunegrid <- expand.grid(.mtry=6)
rf_default <- train(Loa0_Status~.,
data=training1,
method='rf',
metric='Accuracy',
tuneGrid=tunegrid,
trControl=trctrl)
print(rf_default)
plot(rf_default)
confusionMatrix(table(test_pred_grid,testing1$Loa0_Status))
rfPredict <- predict(rf_default,newdata = testing )
#Get the confusion matrix to see accuracy value and other parameter values
confusionMatrix(rfPredict, testing$Loa0_Status )
#svm
data<-real_data
library('caret')
str(data)
head(data)
#changing to numeric
data$Ge0der =as.numeric(as.factor(data$Ge0der))
data$Ge0der
data$Married =as.numeric(as.factor(data$Married))
data$Married
data$Dependents=as.numeric(as.factor(data$Dependents))
data$Dependents
data$Educatio0=as.numeric(as.factor(data$Educatio0))
data$Educatio0
data$Self_Emplo1ed=as.numeric(as.factor(data$Self_Emplo1ed))
data$Self_Emplo1ed
data$Propert1_Area=as.numeric(as.factor(data$Propert1_Area))
data$Propert1_Area
data <- data[c(-1)]
str(data)
set.seed(3033)
intrain <- createDataPartition(y= data$Loa0_Status , p=0.7,list = FALSE)
training <- data[intrain,]
testing <- data[-intrain,]
dim(training);
dim(testing);
anyNA(data)
summary(data)
#factorizing
training[["Loa0_Status"]] = factor(training[["Loa0_Status"]])
trctrl <- trainControl(method = "repeatedcv" , number = 10, repeats = 3)
svm_linear <- train(Loa0_Status~.,data = training, method = "svmLinear"
,trControl = trctrl
, preProcess = c("center" , "scale"),
tuneLength = 10)
svm_linear
test_predict <- predict(svm_linear,newdata = testing)
test_predict
confusionMatrix(table(test_predict,testing$Loa0_Status))
length(data$Loa0_Status)
length(test_predict)
length(testing)
grid <- expand.grid(C= c(0.01,0.05,0.1,0.25,0.5,0.75,1,1.25,1.5,1.75,2.5))
set.seed(3233)
svm_linear_grid <-train(Loa0_Status~. , data = training,method="svmLinear"
, trControl = trctrl,
preProcess = c("center","scale"),
tuneGrid = grid,
tuneLength = 10)
svm_linear_grid
plot(svm_linear_grid)
svm_linear_grid
tunegrid <- expand.grid(.mtry=6)
rf_default <- train(Loa0_Status~.,
data=training1,
method='rf',
metric='Accuracy',
tuneGrid=tunegrid,
trControl=trctrl)
print(rf_default)
plot(rf_default)
